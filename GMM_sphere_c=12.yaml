data:
  type: 'GMM_sphere'
  Xdim_flow: 2 
  c: 12
  indicator: False
  num_means: 10
  
CNF:
  dynamic: True
  hid_dims: '32-32'
  S_ls: [3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3] 
  hk_blocks: [0.05, 0.05, 0.05,0.05,0.05,0.05,0.05,0.05,0.10,0.10,0.10,0.10,0.10,0.10,0.10,0.10,0.10,0.50,0.50,0.50,0.50,0.50,0.50,0.50,0.50,0.50,0.50,0.50,0.50,0.50,0.50,0.50,0.50,0.50,0.50,0.50,0.50] # GMM6

training:
  #################################################################################
  ## For GMM experiments:
  ## We use the Type II loss, as discussed in "The objective" of Appendix C.1.
  ## The first term in the loss is replaced with: -\nabla \log q(x(t_k)) \cdot v_k(x(t_k))
  #################################################################################
  loss_type: 'Type_II'
  ntr: 100000
  nte: 5000
  add_diffuse: None
  load_checkpoint: True
  warm_start: True 
  batch_size: 1000 
  block_idxes: [1,2,3,4,5,6,7,8,9,10,11,12] # Number of blocks
  clip_grad: True
  tot_iters: 1000  # This will be automatically set as 500 if Langevin adjustment is used
  lr: 0.0001

sampling:
  nsamples: 20000

eval:
  viz_freq: 500 
  folder_suffix: '' 